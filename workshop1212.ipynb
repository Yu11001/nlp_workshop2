{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\24746\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\24746\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\24746\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "dataset = pd.read_csv('data/IMDB_Dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 1: Text Cleaning</h2>\n",
    "<h5>Remove special chars, numbers, and extra spaces</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove head and tail space and lowercasing\n",
    "dataset['review'] = dataset['review'].fillna('').str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove emoticons and symbols\n",
    "emoticon_pattern = re.compile(\"[\"  \n",
    "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    u\"\\U00002500-\\U00002BEF\"  # Chinese characters\n",
    "    u\"\\U00002702-\\U000027B0\"\n",
    "    \"]+\", flags=re.UNICODE)\n",
    "\n",
    "dataset['review'] = dataset['review'].str.replace(emoticon_pattern, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove numbers and special chars\n",
    "dataset['review'] = dataset['review'].str.replace(r'[^a-z\\s]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "dataset['sentences'] = dataset['review'].map(sent_tokenize)\n",
    "dataset['words'] = dataset['review'].map(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "dataset['words'] = dataset['words'].map(lambda words: [word for word in words if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply stemmer\n",
    "stemmer = PorterStemmer()\n",
    "dataset['stemmed_words'] = dataset['words'].map(lambda words: [stemmer.stem(word) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "dataset['lemmatized_words'] = dataset['stemmed_words'].map(lambda words: [lemmatizer.lemmatize(word) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment  \\\n",
      "0  one of the other reviewers has mentioned that ...  positive   \n",
      "1  a wonderful little production br br the filmin...  positive   \n",
      "2  i thought this was a wonderful way to spend ti...  positive   \n",
      "3  basically theres a family where a little boy j...  negative   \n",
      "4  petter matteis love in the time of money is a ...  positive   \n",
      "\n",
      "                                           sentences  \\\n",
      "0  [one of the other reviewers has mentioned that...   \n",
      "1  [a wonderful little production br br the filmi...   \n",
      "2  [i thought this was a wonderful way to spend t...   \n",
      "3  [basically theres a family where a little boy ...   \n",
      "4  [petter matteis love in the time of money is a...   \n",
      "\n",
      "                                               words  \\\n",
      "0  [one, reviewers, mentioned, watching, oz, epis...   \n",
      "1  [wonderful, little, production, br, br, filmin...   \n",
      "2  [thought, wonderful, way, spend, time, hot, su...   \n",
      "3  [basically, theres, family, little, boy, jake,...   \n",
      "4  [petter, matteis, love, time, money, visually,...   \n",
      "\n",
      "                                       stemmed_words  \\\n",
      "0  [one, review, mention, watch, oz, episod, youl...   \n",
      "1  [wonder, littl, product, br, br, film, techniq...   \n",
      "2  [thought, wonder, way, spend, time, hot, summe...   \n",
      "3  [basic, there, famili, littl, boy, jake, think...   \n",
      "4  [petter, mattei, love, time, money, visual, st...   \n",
      "\n",
      "                                    lemmatized_words  \n",
      "0  [one, review, mention, watch, oz, episod, youl...  \n",
      "1  [wonder, littl, product, br, br, film, techniq...  \n",
      "2  [thought, wonder, way, spend, time, hot, summe...  \n",
      "3  [basic, there, famili, littl, boy, jake, think...  \n",
      "4  [petter, mattei, love, time, money, visual, st...  \n"
     ]
    }
   ],
   "source": [
    "dataset.to_csv('data/processed_dataset.csv', index=False)\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment  \\\n",
      "0  one of the other reviewers has mentioned that ...  positive   \n",
      "1  a wonderful little production br br the filmin...  positive   \n",
      "2  i thought this was a wonderful way to spend ti...  positive   \n",
      "3  basically theres a family where a little boy j...  negative   \n",
      "4  petter matteis love in the time of money is a ...  positive   \n",
      "\n",
      "                                           sentences  \\\n",
      "0  [one of the other reviewers has mentioned that...   \n",
      "1  [a wonderful little production br br the filmi...   \n",
      "2  [i thought this was a wonderful way to spend t...   \n",
      "3  [basically theres a family where a little boy ...   \n",
      "4  [petter matteis love in the time of money is a...   \n",
      "\n",
      "                                               words  \\\n",
      "0  [one, reviewers, mentioned, watching, oz, epis...   \n",
      "1  [wonderful, little, production, br, br, filmin...   \n",
      "2  [thought, wonderful, way, spend, time, hot, su...   \n",
      "3  [basically, theres, family, little, boy, jake,...   \n",
      "4  [petter, matteis, love, time, money, visually,...   \n",
      "\n",
      "                                       stemmed_words  \\\n",
      "0  [one, review, mention, watch, oz, episod, youl...   \n",
      "1  [wonder, littl, product, br, br, film, techniq...   \n",
      "2  [thought, wonder, way, spend, time, hot, summe...   \n",
      "3  [basic, there, famili, littl, boy, jake, think...   \n",
      "4  [petter, mattei, love, time, money, visual, st...   \n",
      "\n",
      "                                    lemmatized_words  flesch_score  \\\n",
      "0  [one, review, mention, watch, oz, episod, youl...   -225.955000   \n",
      "1  [wonder, littl, product, br, br, film, techniq...    -94.417222   \n",
      "2  [thought, wonder, way, spend, time, hot, summe...    -84.720000   \n",
      "3  [basic, there, famili, littl, boy, jake, think...    -46.472782   \n",
      "4  [petter, mattei, love, time, money, visual, st...   -152.411522   \n",
      "\n",
      "  fk_grade_level  \n",
      "0            118  \n",
      "1             65  \n",
      "2             64  \n",
      "3             51  \n",
      "4             89  \n"
     ]
    }
   ],
   "source": [
    "from readability import Readability\n",
    "\n",
    "def calculate_readability(text):\n",
    "    try:\n",
    "        r = Readability(text)\n",
    "        flesch = r.flesch().score\n",
    "        fk_grade = r.flesch_kincaid().grade_level \n",
    "        return flesch, fk_grade\n",
    "    except Exception as e:\n",
    "        return None, None\n",
    "\n",
    "dataset[['c', 'fk_grade_level']] = dataset['review'].apply(\n",
    "    lambda x: pd.Series(calculate_readability(x))\n",
    ")\n",
    "\n",
    "dataset.to_csv('data/processed_with_readability.csv', index=False)\n",
    "\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        118\n",
      "1         65\n",
      "2         64\n",
      "3         51\n",
      "4         89\n",
      "        ... \n",
      "49995     73\n",
      "49996     45\n",
      "49997     89\n",
      "49998     82\n",
      "49999     49\n",
      "Name: fk_grade_level, Length: 50000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataset['fk_grade_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       -225.955000\n",
      "1        -94.417222\n",
      "2        -84.720000\n",
      "3        -46.472782\n",
      "4       -152.411522\n",
      "            ...    \n",
      "49995   -101.285625\n",
      "49996    -33.745000\n",
      "49997   -151.576419\n",
      "49998   -134.029526\n",
      "49999    -38.555000\n",
      "Name: flesch_score, Length: 50000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(dataset['flesch_score'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
